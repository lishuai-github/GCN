## 卷积神经网络
### 经典卷积神经网络 LeNet
LeNet代码实现
```python
import torch
from torch import nn
from d2l import torch as d2l

class Reshape(torch.nn.Module):
    def forward(self, x):
        return x.view(-1, 1, 28, 28)

net = torch.nn.Sequential(Reshape(), nn.Conv2d(1, 6, kernel_size=5,
                                               padding=2), nn.Sigmoid(),
                          nn.AvgPool2d(kernel_size=2, stride=2),
                          nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
                          nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
                          nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
                          nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10))
```
卷积网络把压缩空间信息放入通道信息中，所以在卷积的过程中通道数增加而空间大小减少。提取其中的模式。

Q&A：

1.时序数据可以做一维的卷积。
2.压缩方法：高宽减半的同时通道数加倍。
3.通道可能是匹配某种模式，低层可能模式简单。
4.CNN explainer 
5.现在深度学习有在很大的数据集上与训练了，使用的时候需要很少的数据集。
6.
